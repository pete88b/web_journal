{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp service.filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Filesystem\n",
    "\n",
    "> Service implementation that stores data in the local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json,time,datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def posts_list_to_dict(posts,key='id'):\n",
    "    \"Convert a list of dictionaries to a dictionary of dictionaries\"\n",
    "    return {post[key]:post for post in posts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts=[dict(id=0,tag='a'),dict(id=-1,tag='B')]\n",
    "expected={0:posts[0],-1:posts[1]}\n",
    "assert expected==posts_list_to_dict(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ServiceFilesystem:\n",
    "    # TODO: DRY\n",
    "    def __init__(self,data_dir):\n",
    "        self.data_dir=Path(data_dir)\n",
    "        self.data_dir.mkdir(parents=True,exist_ok=True)\n",
    "        \n",
    "    def read_user_by_id(self,id): \n",
    "        if (self.data_dir/'users.json').is_file():\n",
    "            with open(self.data_dir/'users.json') as f: \n",
    "                for user in json.load(f):\n",
    "                    if user['id']==id: return user\n",
    "        return None\n",
    "    \n",
    "    def read_user_by_username(self,username): \n",
    "        if (self.data_dir/'users.json').is_file():\n",
    "            with open(self.data_dir/'users.json') as f: \n",
    "                for user in json.load(f):\n",
    "                    if user['username']==username: return user\n",
    "        return None\n",
    "    \n",
    "    def create_user(self,username,password): \n",
    "        users=[]\n",
    "        if (self.data_dir/'users.json').is_file():\n",
    "            with open(self.data_dir/'users.json') as f: users=json.load(f)\n",
    "        id=round(time.time()*1000)\n",
    "        users.append(dict(id=id,username=username,password=password))\n",
    "        with open(self.data_dir/'users.json','w') as f: json.dump(users,f)\n",
    "        return id\n",
    "    \n",
    "    def _add_username(self,post):\n",
    "        # TODO: check how slow this is ...\n",
    "        user=self.read_user_by_id(post['author_id'])\n",
    "        post['username']='Unknown user' if user is None else user['username'] \n",
    "        return post\n",
    "    \n",
    "    def read_posts_by_author_id(self,author_id): \n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            with open(self.data_dir/f'posts-{author_id}.json') as f: \n",
    "                return [self._add_username(p) for p in json.load(f) if p['is_deleted']==0]\n",
    "        return []\n",
    "    \n",
    "    def read_post_by_id(self,author_id,id): \n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            with open(self.data_dir/f'posts-{author_id}.json') as f:\n",
    "                for post in json.load(f):\n",
    "                    if post['id']==id: return self._add_username(post)\n",
    "        return None\n",
    "    \n",
    "    def create_post(self,author_id,title,body):\n",
    "        posts=[]\n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            with open(self.data_dir/f'posts-{author_id}.json') as f: posts=json.load(f)\n",
    "        id=round(time.time()*1000)\n",
    "        _now=datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        posts.insert(0,dict(id=id,author_id=author_id,title=title,body=body,created=_now,is_deleted=0))\n",
    "        with open(self.data_dir/f'posts-{author_id}.json','w') as f: json.dump(posts,f)\n",
    "        return id\n",
    "    \n",
    "    def update_post_by_id(self,author_id,id,title,body):\n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            with open(self.data_dir/f'posts-{author_id}.json') as f: posts = json.load(f)\n",
    "            for post in posts:\n",
    "                if post['id']==id: \n",
    "                    post['title'],post['body']=title,body\n",
    "                    with open(self.data_dir/f'posts-{author_id}.json','w') as f: json.dump(posts,f)\n",
    "                    return post\n",
    "        return None\n",
    "    \n",
    "    def delete_post_by_id(self,author_id,id):\n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            with open(self.data_dir/f'posts-{author_id}.json') as f: posts = json.load(f)\n",
    "            for post in posts:\n",
    "                if post['id']==id: \n",
    "                    post['is_deleted']=1\n",
    "                    with open(self.data_dir/f'posts-{author_id}.json','w') as f: json.dump(posts,f)\n",
    "                    return post\n",
    "        return None\n",
    "    \n",
    "    def prepare_posts_file_by_author_id(self,author_id):\n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            return self.data_dir,f'posts-{author_id}.json'\n",
    "        return None,None\n",
    "    \n",
    "    def upload_posts_from_file(self,author_id,file):\n",
    "        # TODO: handle non-json formats\n",
    "        with open(file) as f: \n",
    "            posts=json.load(f)\n",
    "            for post in posts: post['author_id']=author_id\n",
    "            posts=posts_list_to_dict(posts)\n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            with open(self.data_dir/f'posts-{author_id}.json') as f: \n",
    "                posts.update(posts_list_to_dict(json.load(f)))\n",
    "        posts=sorted(posts.values(), key=lambda post: post['id'], reverse=True)\n",
    "        with open(self.data_dir/f'posts-{author_id}.json','w') as f: json.dump(posts,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = tempfile.mkdtemp()\n",
    "try:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    post=service._add_username(dict(author_id=123))\n",
    "    assert 'Unknown user'==post['username']\n",
    "finally:\n",
    "    shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compare_post(expected,actal):\n",
    "    \"Check values match for all keys in `expected`, which might not be all keys in `actual`\"\n",
    "    for k in expected.keys(): assert expected[k]==actal[k]\n",
    "\n",
    "temp_path = tempfile.mkdtemp()\n",
    "try:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    # user section\n",
    "    assert service.read_user_by_id(1234) is None\n",
    "    assert service.read_user_by_username('test.user') is None\n",
    "    user_id=service.create_user('test.user','badPassword')\n",
    "    expected_user=dict(id=user_id,username='test.user',password='badPassword')\n",
    "    assert service.read_user_by_id(user_id)==expected_user\n",
    "    assert service.read_user_by_username('test.user')==expected_user\n",
    "    # post section\n",
    "    assert service.read_posts_by_author_id(123)==[]\n",
    "    assert service.read_posts_by_author_id(user_id)==[]\n",
    "    assert service.read_post_by_id(user_id,123) is None\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}','body')\n",
    "    post_id=service.create_post(user_id,'title','body')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}2','body')\n",
    "    # don't add created to `expected_post` as we don't know what it's value will be\n",
    "    expected_post=dict(id=post_id,author_id=user_id,title='title',body='body',username='test.user',is_deleted=0)\n",
    "    posts=service.read_posts_by_author_id(user_id)\n",
    "    assert len(posts)==7\n",
    "    _compare_post(expected_post,posts[3])\n",
    "    assert isinstance(posts[3]['created'],str)\n",
    "    post=service.read_post_by_id(user_id,post_id)\n",
    "    assert post==posts[3]\n",
    "    assert post['is_deleted']==0\n",
    "    assert post!=service.delete_post_by_id(user_id,post_id)\n",
    "    expected_post['is_deleted']=1\n",
    "    # deleted posts are readable by ID ...\n",
    "    _compare_post(expected_post,service.read_post_by_id(user_id,post_id))\n",
    "    # but are not returned when reading all posts by author\n",
    "    assert len(service.read_posts_by_author_id(user_id))==6\n",
    "    # test prep download\n",
    "    directory,filename=service.prepare_posts_file_by_author_id(user_id)\n",
    "    assert isinstance(directory,Path)\n",
    "    assert isinstance(filename,str)\n",
    "    assert filename==f'posts-{user_id}.json'\n",
    "    assert (directory/filename).is_file()\n",
    "    # test upload\n",
    "    shutil.copyfile(directory/filename,directory/'posts2upload')\n",
    "    posts=service.read_posts_by_author_id(user_id)\n",
    "    service.upload_posts_from_file(user_id,directory/'posts2upload') # makes no difference\n",
    "    assert posts==service.read_posts_by_author_id(user_id)\n",
    "    [service.delete_post_by_id(user_id,post['id']) for post in posts]\n",
    "    service.upload_posts_from_file(user_id,directory/'posts2upload')\n",
    "    assert []==service.read_posts_by_author_id(user_id) # they are all still deleted\n",
    "    (directory/filename).unlink()\n",
    "    service.upload_posts_from_file(user_id,directory/'posts2upload')\n",
    "    assert posts==service.read_posts_by_author_id(user_id)\n",
    "finally:\n",
    "    shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def before_request(app):\n",
    "    return ServiceFilesystem(app.config['DATA_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def after_request(app,service):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_service(app):\n",
    "    print('service.filesystem.init_service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 40a_service_db.ipynb.\n",
      "Converted 40b_service_filesystem.ipynb.\n",
      "Converted 50_web_app.ipynb.\n",
      "Converted 50b_web_auth.ipynb.\n",
      "Converted 50c_web_blog.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

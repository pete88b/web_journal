{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp service.filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Filesystem\n",
    "\n",
    "> Service implementation that stores data in the local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json,time,datetime,re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import tempfile, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def test_resources():\n",
    "    temp_path = Path(tempfile.mkdtemp())\n",
    "    try:\n",
    "        cwd = get_ipython().run_line_magic('pwd', '')\n",
    "        print('cwd',cwd)\n",
    "        print('temp_path',temp_path)\n",
    "        yield temp_path\n",
    "    finally:\n",
    "        shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def posts_list_to_dict(posts,key='id'):\n",
    "    \"Convert a list of dictionaries to a dictionary of dictionaries\"\n",
    "    return {post[key]:post for post in posts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts=[dict(id=0,tag='a'),dict(id=-1,tag='B')]\n",
    "expected={0:posts[0],-1:posts[1]}\n",
    "assert expected==posts_list_to_dict(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def migrate(data_dir,output_dir=None):\n",
    "    posts_file_re=re.compile(r'posts-(?:\\d{13}).json')\n",
    "    data_dir=Path(data_dir)\n",
    "    output_dir=data_dir if output_dir is None else Path(output_dir)\n",
    "    for f_name in data_dir.iterdir():\n",
    "        if not posts_file_re.fullmatch(f_name.name): continue\n",
    "        with open(f_name) as f: posts = json.load(f)\n",
    "        if not posts: continue\n",
    "        print('migrating',f_name,'to',output_dir)\n",
    "        if not 'status' in posts[0]:\n",
    "            for post in posts:\n",
    "                post['last_updated']=post['created']\n",
    "                post['status']=50 if post['is_deleted']==0 else 20\n",
    "                del post['is_deleted']\n",
    "        # subsequent migrations might do something like\n",
    "        # if not 'other_key' in posts[0]: ...\n",
    "        with open(output_dir/f_name.name,'w') as f: json.dump(posts,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd C:\\Users\\Butterp\\github\\pete88b\\web_journal\n",
      "temp_path C:\\Users\\Butterp\\AppData\\Local\\Temp\\tmp6i9zna2u\n",
      "migrating test\\original-format\\posts-1614707380557.json to C:\\Users\\Butterp\\AppData\\Local\\Temp\\tmp6i9zna2u\n"
     ]
    }
   ],
   "source": [
    "with test_resources() as temp_path:\n",
    "    migrate('test/original-format',temp_path)\n",
    "    with open(Path(temp_path)/'posts-1614707380557.json') as f: posts = json.load(f)\n",
    "    assert posts[0]=={\n",
    "        \"id\": 1614810438150,\n",
    "        \"author_id\": 1614707380557,\n",
    "        \"title\": \"plan: same as yesterday :-(\",\n",
    "        \"body\": \"\",\n",
    "        \"created\": \"2021-03-03 22:27:18\",\n",
    "        \"last_updated\": \"2021-03-03 22:27:18\",\n",
    "        \"status\": 50}\n",
    "    assert posts[2]=={\n",
    "        \"id\": 1614276006392,\n",
    "        \"author_id\": 1614707380557,\n",
    "        \"title\": \"tt\",\n",
    "        \"body\": \"130\",\n",
    "        \"created\": \"2021-02-25 18:00:06\",\n",
    "        \"last_updated\": \"2021-02-25 18:00:06\",\n",
    "        \"status\": 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ServiceFilesystem:\n",
    "    # TODO: DRY\n",
    "    def __init__(self,data_dir):\n",
    "        self.data_dir=Path(data_dir)\n",
    "        self.data_dir.mkdir(parents=True,exist_ok=True)\n",
    "        \n",
    "    def read_user_by_id(self,id): \n",
    "        if (self.data_dir/'users.json').is_file():\n",
    "            with open(self.data_dir/'users.json') as f: \n",
    "                for user in json.load(f):\n",
    "                    if user['id']==id: return user\n",
    "        return None\n",
    "    \n",
    "    def read_user_by_username(self,username): \n",
    "        if (self.data_dir/'users.json').is_file():\n",
    "            with open(self.data_dir/'users.json') as f: \n",
    "                for user in json.load(f):\n",
    "                    if user['username']==username: return user\n",
    "        return None\n",
    "    \n",
    "    def create_user(self,username,password): \n",
    "        users=[]\n",
    "        if (self.data_dir/'users.json').is_file():\n",
    "            with open(self.data_dir/'users.json') as f: users=json.load(f)\n",
    "        id=round(time.time()*1000)\n",
    "        users.append(dict(id=id,username=username,password=password))\n",
    "        with open(self.data_dir/'users.json','w') as f: json.dump(users,f)\n",
    "        return id\n",
    "    \n",
    "    def _add_username(self,post):\n",
    "        # TODO: check how slow this is ...\n",
    "        user=self.read_user_by_id(post['author_id'])\n",
    "        post['username']='Unknown user' if user is None else user['username'] \n",
    "        return post\n",
    "    \n",
    "    def _posts(self,author_id):\n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            with open(self.data_dir/f'posts-{author_id}.json') as f: \n",
    "                return json.load(f)\n",
    "        return []\n",
    "    \n",
    "    def read_posts_by_author_id(self,author_id): \n",
    "        return [self._add_username(p) for p in self._posts(author_id) if p['status']>30]\n",
    "        \n",
    "    def read_post_by_id(self,author_id,id): \n",
    "        for post in self._posts(author_id):\n",
    "            if post['id']==id: return self._add_username(post)\n",
    "        return None\n",
    "    \n",
    "    def _now(self):\n",
    "        return datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    def create_post(self,author_id,title,body):\n",
    "        posts=self._posts(author_id)\n",
    "        id,_now=round(time.time()*1000),self._now()\n",
    "        posts.insert(0,dict(id=id,author_id=author_id,title=title,body=body,\n",
    "                            created=_now,last_updated=_now,status=50))\n",
    "        with open(self.data_dir/f'posts-{author_id}.json','w') as f: json.dump(posts,f)\n",
    "        return id\n",
    "    \n",
    "    def update_post_by_id(self,author_id,id,keys,values):\n",
    "        posts=self._posts(author_id)\n",
    "        for post in posts:\n",
    "            if post['id']==id: \n",
    "                for key,value in zip(keys,values): post[key]=value\n",
    "                post['last_updated']=self._now()\n",
    "                with open(self.data_dir/f'posts-{author_id}.json','w') as f: json.dump(posts,f)\n",
    "                return post\n",
    "        return None\n",
    "        \n",
    "    def prepare_posts_file_by_author_id(self,author_id):\n",
    "        if (self.data_dir/f'posts-{author_id}.json').is_file():\n",
    "            return self.data_dir,f'posts-{author_id}.json'\n",
    "        return None,None\n",
    "    \n",
    "    def upload_posts_from_file(self,author_id,file):\n",
    "        # TODO: handle non-json formats\n",
    "        with open(file) as f: \n",
    "            posts=json.load(f)\n",
    "            for post in posts: post['author_id']=author_id\n",
    "            posts=posts_list_to_dict(posts)\n",
    "        posts.update(posts_list_to_dict(self._posts(author_id)))\n",
    "        posts=sorted(posts.values(), key=lambda post: post['id'], reverse=True)\n",
    "        with open(self.data_dir/f'posts-{author_id}.json','w') as f: json.dump(posts,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test user functions\n",
    "with test_resources() as temp_path:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    assert service.read_user_by_id(1234) is None\n",
    "    assert service.read_user_by_username('test.user') is None\n",
    "    user_id=service.create_user('test.user','badPassword')\n",
    "    expected_user=dict(id=user_id,username='test.user',password='badPassword')\n",
    "    assert service.read_user_by_id(user_id)==expected_user\n",
    "    assert service.read_user_by_username('test.user')==expected_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with test_resources() as temp_path:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    post=service._add_username(dict(author_id=123))\n",
    "    assert 'Unknown user'==post['username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compare_post(expected,actal):\n",
    "    \"Check values match for all keys in `expected`, which might not be all keys in `actual`\"\n",
    "    for k in expected.keys(): assert expected[k]==actal[k], f'{k}: expected {expected[k]} but found {actal[k]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test post functions\n",
    "with test_resources() as temp_path:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    user_id=service.create_user('test.user','badPassword')\n",
    "    assert service.read_posts_by_author_id(123)==[]\n",
    "    assert service.read_posts_by_author_id(user_id)==[]\n",
    "    assert service.read_post_by_id(user_id,123) is None\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}','body')\n",
    "    post_id=service.create_post(user_id,'title','body')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}2','body')\n",
    "    # don't add created to `expected_post` as we don't know what it's value will be\n",
    "    expected_post=dict(id=post_id,author_id=user_id,title='title',body='body',username='test.user',status=50)\n",
    "    posts=service.read_posts_by_author_id(user_id)\n",
    "    assert len(posts)==7\n",
    "    _compare_post(expected_post,posts[3])\n",
    "    assert isinstance(posts[3]['created'],str)\n",
    "    post=service.read_post_by_id(user_id,post_id)\n",
    "    assert post==posts[3]\n",
    "    assert post['status']==50\n",
    "    assert post!=service.update_post_by_id(user_id,post_id,['status'],[20])\n",
    "    # test prep download\n",
    "    directory,filename=service.prepare_posts_file_by_author_id(user_id)\n",
    "    assert isinstance(directory,Path)\n",
    "    assert isinstance(filename,str)\n",
    "    assert filename==f'posts-{user_id}.json'\n",
    "    assert (directory/filename).is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test upload\n",
    "with test_resources() as temp_path:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    user_id=service.create_user('test.user','badPassword')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}','body')\n",
    "    post_id=service.create_post(user_id,'title','body')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}2','body')\n",
    "    filename=f'posts-{user_id}.json'\n",
    "    shutil.copyfile(temp_path/filename,temp_path/'posts2upload')\n",
    "    posts=service.read_posts_by_author_id(user_id)\n",
    "    service.upload_posts_from_file(user_id,temp_path/'posts2upload') # makes no difference\n",
    "    actual_posts=service.read_posts_by_author_id(user_id)\n",
    "    assert posts==actual_posts, f'expected={posts}\\nactual={actual_posts}'\n",
    "    [service.update_post_by_id(user_id,post['id'],['status'],[20]) for post in posts]\n",
    "    service.upload_posts_from_file(user_id,temp_path/'posts2upload')\n",
    "    assert []==service.read_posts_by_author_id(user_id) # they are all still deleted\n",
    "    (temp_path/filename).unlink()\n",
    "    service.upload_posts_from_file(user_id,temp_path/'posts2upload')\n",
    "    actual_posts=service.read_posts_by_author_id(user_id)\n",
    "    assert posts==actual_posts, f'expected={posts}\\nactual={actual_posts}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "title: expected title22 but found title12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-23263485172a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1615194300275\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'author_id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1615194300273\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'title12'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'created'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'2021-03-08 09:05:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'last_updated'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'2021-03-08 09:05:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'status'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'username'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'test.user'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1615194300274\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'author_id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1615194300273\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'title1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'created'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'2021-03-08 09:05:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'last_updated'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'2021-03-08 09:05:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'status'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'username'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'test.user'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1615194300273\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'author_id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1615194300273\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'title0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'created'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'2021-03-08 09:05:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'last_updated'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'2021-03-08 09:05:00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'status'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'username'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'test.user'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0m_compare_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f8071dd4a1a1>\u001b[0m in \u001b[0;36m_compare_post\u001b[1;34m(expected, actal)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_compare_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"Check values match for all keys in `expected`, which might not be all keys in `actual`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexpected\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mexpected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mactal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{k}: expected {expected[k]} but found {actal[k]}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: title: expected title22 but found title12"
     ]
    }
   ],
   "source": [
    "# expected=[{'id': 1615194300275, 'author_id': 1615194300273, 'title': 'title22', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300275, 'author_id': 1615194300273, 'title': 'title12', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300274, 'author_id': 1615194300273, 'title': 'title02', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300274, 'author_id': 1615194300273, 'title': 'title', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300274, 'author_id': 1615194300273, 'title': 'title2', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300274, 'author_id': 1615194300273, 'title': 'title1', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300273, 'author_id': 1615194300273, 'title': 'title0', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}]\n",
    "# found=[{'id': 1615194300275, 'author_id': 1615194300273, 'title': 'title12', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300274, 'author_id': 1615194300273, 'title': 'title1', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}, {'id': 1615194300273, 'author_id': 1615194300273, 'title': 'title0', 'body': 'body', 'created': '2021-03-08 09:05:00', 'last_updated': '2021-03-08 09:05:00', 'status': 50, 'username': 'test.user'}]\n",
    "# for i in range(len(expected)):\n",
    "#     _compare_post(expected[i],found[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test delete\n",
    "with test_resources() as temp_path:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    user_id=service.create_user('test.user','badPassword')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}','body')\n",
    "    post_id=service.create_post(user_id,'title','body')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}2','body')\n",
    "    post=service.read_post_by_id(user_id,post_id)\n",
    "    assert post['created']==post['last_updated']\n",
    "    assert post['status']==50\n",
    "    time.sleep(1) # wait 1s so that last_updated is different\n",
    "    assert post!=service.update_post_by_id(user_id,post_id,['status'],[20])\n",
    "    post=service.read_post_by_id(user_id,post_id)\n",
    "    assert post['status']==20\n",
    "    assert post['created']!=post['last_updated']\n",
    "    # deleted posts are readable by ID ...\n",
    "    expected_post=dict(id=post_id,author_id=user_id,title='title',body='body',username='test.user',status=20)\n",
    "    _compare_post(expected_post,service.read_post_by_id(user_id,post_id))\n",
    "    # but are not returned when reading all posts by author\n",
    "    assert len(service.read_posts_by_author_id(user_id))==6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test update\n",
    "with test_resources() as temp_path:\n",
    "    service=ServiceFilesystem(temp_path)\n",
    "    user_id=service.create_user('test.user','badPassword')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}','body')\n",
    "    post_id=service.create_post(user_id,'title','body')\n",
    "    for i in range(3): service.create_post(user_id,f'title{i}2','body')\n",
    "    post=service.read_post_by_id(user_id,post_id)\n",
    "    assert post['created']==post['last_updated']\n",
    "    expected_post=dict(id=post_id,author_id=user_id,title='title',body='body',username='test.user',status=50)\n",
    "    _compare_post(expected_post,post)\n",
    "    time.sleep(1) # wait 1s so that last_updated is different\n",
    "    updated_post=service.update_post_by_id(user_id,post_id,['title','body'],['new title','new-body'])\n",
    "    expected_post['title']='new title'\n",
    "    expected_post['body']='new-body'\n",
    "    post=service.read_post_by_id(user_id,post_id)\n",
    "    assert post['created']!=post['last_updated']\n",
    "    _compare_post(expected_post,post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def before_request(app):\n",
    "    return ServiceFilesystem(app.config['DATA_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def after_request(app,service):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_service(app):\n",
    "    print('service.filesystem.init_service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI\n",
    "\n",
    "> Command line tools for working with storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from storage_tools.core import *\n",
    "from fastcore.script import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def upload_dataset(storage_name:Param('Section name in config',str),\n",
    "                   dataset_name:Param('Dataset name',str),\n",
    "                   config_name:Param('Path to config',str)='secrets/settings.ini',\n",
    "                   dataset_version:Param('Dataset version',str)='patch'):\n",
    "    \"Create a new dataset archive and upload it to remote storage\"\n",
    "    r=new_storage_client(storage_name,config_name).upload_dataset(dataset_name,dataset_version)\n",
    "    print('Dataset uploaded to',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def download_dataset(storage_name:Param('Section name in config',str),\n",
    "                     dataset_name:Param('Dataset name',str),\n",
    "                     config_name:Param('Path to config',str)='secrets/settings.ini',\n",
    "                     dataset_version:Param('Dataset version',str)='latest',\n",
    "                     overwrite:Param('If True, delete the dataset and re-download',bool)=False):\n",
    "    \"Download a dataset archive from remote storage\"\n",
    "    r=new_storage_client(storage_name,config_name).download_dataset(dataset_name,dataset_version,overwrite)\n",
    "    print('Dataset downloaded to',r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a project folder containing\n",
    "\n",
    "<pre>\n",
    "project_root\n",
    "  &angrt; data\n",
    "    &angrt; mnist\n",
    "      &angrt; hand_drawn_digits\n",
    "        &angrt; digit0.png\n",
    "        &angrt; digit1.png\n",
    "        &angrt; ...\n",
    "  &angrt; secrets\n",
    "    &angrt; settings.ini\n",
    "&angrt; main.py\n",
    "</pre>\n",
    "\n",
    "where `settings.ini` contains\n",
    "\n",
    "```\n",
    "[DEFAULT]\n",
    "local_path=data\n",
    "\n",
    "[azure_demo]\n",
    "storage_client=storage_tools.core.AzureStorageClient\n",
    "conn_str=<A connection string to an Azure Storage account without credential>\n",
    "credential=<The credentials with which to authenticate>\n",
    "container=<The name of a storage container>\n",
    "```\n",
    "\n",
    "We can\n",
    "\n",
    "### Create a new version of a dataset\n",
    "\n",
    "```\n",
    "upload_dataset azure_demo mnist/hand_drawn_digits --dataset_version=major\n",
    "```\n",
    "\n",
    "### Download the latest version of a dataset\n",
    "\n",
    "Feel free to delete your local copy of this dataset (from data) to download from azure storage.\n",
    "\n",
    "```\n",
    "download_dataset azure_demo mnist/hand_drawn_digits\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "def _rmtree(p):\n",
    "    try: shutil.rmtree(p)\n",
    "    except FileNotFoundError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_local_test_data():\n",
    "    test_files=['a/b/test_data.txt','a/b/more_test_data.txt']\n",
    "    for i,f in enumerate(test_files):\n",
    "        f='test/local_path/'+f\n",
    "        Path(f).parent.mkdir(parents=True,exist_ok=True)\n",
    "        with open(f, 'w') as _file: _file.write(f'a little bit of data {i}')\n",
    "    return test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset uploaded to test\\storage_area\\a.3.0.0.zip\n",
      "Dataset uploaded to test\\storage_area\\a.3.0.1.zip\n",
      "Dataset downloaded to test\\local_path\\a.3.0.1\n",
      "Dataset downloaded to test\\local_path\\a.3.0.0\n",
      "Dataset downloaded to test\\local_path\\a.3.0.0\n",
      "Dataset downloaded to test\\local_path\\a.3.0.0\n"
     ]
    }
   ],
   "source": [
    "for p in ['test/local_path','test/storage_area']: _rmtree(p)\n",
    "\n",
    "test_files=_make_local_test_data()\n",
    "\n",
    "def _t(expected,upload_name,version='patch'):\n",
    "    upload_dataset('local_test',upload_name,'test/settings.ini',version)\n",
    "_t('a.3.0.0.zip','a','3.0.0')\n",
    "_t('a.3.0.1.zip','a')\n",
    "# TODO: check zip contents\n",
    "_rmtree('test/local_path/a.3.0.0')\n",
    "_rmtree('test/local_path/a.3.0.1')\n",
    "\n",
    "download_dataset('local_test','a','test/settings.ini')\n",
    "download_dataset('local_test','a','test/settings.ini','3.0.0')\n",
    "download_dataset('local_test','a','test/settings.ini','3.0.0')\n",
    "download_dataset('local_test','a','test/settings.ini','3.0.0',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['test/local_path','test/storage_area']: _rmtree(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
